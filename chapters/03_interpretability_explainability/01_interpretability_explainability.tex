
Interpretability and explainability are two important concepts in the field of machine learning and artificial intelligence lately.
Researchers and practitioners are using these concepts interchangeably as they are closely related, but it is important to understand the difference between them.

By the definition of by Cambridge Dictionary~\cite{dictionary2017cambridge}, if something is interpretable, \emph{it is possible to find its meaning or possible to find a particular meaning in it}.
The verb to explain means \emph{to make something clear or easy to understand by describing or giving information about it}.
Both definitions are related to the concept of meaning, but the way to achieve it is different.
The main differentiator between these two is that meaning can be found intrinsically in interpretable things while through explanation, the meaning is given by the understanding through the description or additional information.

In the context of machine learning, definition of interpretability varies.
It has been defined as the ability to explain or to present in understandable terms to a
human ~\cite[Finale]{Finale2017} whle according to~\cite{miller2019explanation} it is defined as \emph{the degree to which a human can understand the cause of a decision}.

Interpretability aims to present a the internal workings of a system in a way that is understandable to humans\cite{gilpin2018explaining}.
%\cite{Linardatos2021}
%\cite{Guidotti2018ASO}
%

\subsection{Machine learning explainability}
Interpretable models include linear regression, generalized linear models, decision trees, and rule-based models, while deep learning models, random forests, and gradient boosting models are considered black-box models~\cite{Guidotti2018ASO}.


Considering interpretability and explainabilioty of machine learning models is important for several reasons, including the detection of biases, evaluation of model robustness or evaluation that only meaningful variables contribute to the model's predictions~\cite{BARREDOARRIETA202082}.


There is also criticism of the on the use of model explanation~\cite{rudin2019stop}

%They are essential for understanding the decisions made by machine learning models. Interpretability refers to the ability to explain the model's predictions in a human-understandable way. Explainability, on the other hand, refers to the ability to explain the model's predictions in a way that is understandable to non-experts. In this chapter, we discuss the importance of interpretability and explainability in machine learning and artificial intelligence, and we explore some of the methods used to achieve these goals. We also discuss the challenges of achieving interpretability and explainability in time series forecasting, and we explore the use of feature importance as a basis for model reasoning.